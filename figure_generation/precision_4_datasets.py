import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ======== 数据集配置 ============
dataset_configs = [
    {'name': 'CAIDA 2016', 'positives': 21, 'samples': 275782},
    {'name': 'CAIDA 2019', 'positives': 42, 'samples': 167074},
    {'name': 'IMC 2010', 'positives': 66, 'samples': 4473},
    {'name': 'CICIDS 2017', 'positives': 10, 'samples': 8278},
]

# 每个数据集下分别准备 3 组数据（填入实际数据字符串）
dataset_raw_data = [
    {
        'minhash': """10000000,20,20,272,8,32,4,10,10,5,200,0.6667,0.9524,0.7843,23.9,11,0.5,0.9
10000000,20,40,272,8,32,4,10,20,10,200,0.625,0.9524,0.7547,23.85,22,0.5,0.9
10000000,20,60,272,8,32,4,10,30,15,200,0.625,0.9524,0.7547,24.5,34,0.5,0.9
10000000,20,80,272,8,32,4,10,40,20,200,0.5882,0.9524,0.7273,24.9,45,0.5,0.9
10000000,20,100,272,8,32,4,10,50,25,200,0.5556,0.9524,0.7018,24.09,56,0.5,0.9
10000000,20,120,272,8,32,4,10,60,30,200,0.5556,0.9524,0.7018,25.33,68,0.5,0.9
10000000,20,140,272,8,32,4,10,70,35,200,0.5278,0.9048,0.6667,25.63,79,0.5,0.9
10000000,20,160,272,8,32,4,10,80,40,200,0.4878,0.9524,0.6452,25.31,90,0.5,0.9
10000000,20,180,272,8,32,4,10,90,45,200,0.5263,0.9524,0.678,26.92,102,0.5,0.9
10000000,20,200,272,8,32,4,10,100,50,200,0.5882,0.9524,0.7273,26.11,113,0.5,0.9
10000000,20,220,272,8,32,4,10,110,55,200,0.5556,0.9524,0.7018,26.76,124,0.5,0.9
10000000,20,240,272,8,32,4,10,120,60,200,0.5405,0.9524,0.6896,27.46,136,0.5,0.9""",
        'maxloghash': """10000000,20,40,272,8,32,4,10,20,10,128,0.1382,1.0,0.2428,20.46,14,0.5,0.9
10000000,20,80,272,8,32,4,10,40,20,128,0.0837,1.0,0.1545,20.07,28,0.5,0.9
10000000,20,120,272,8,32,4,10,60,30,128,0.0614,1.0,0.1157,19.26,42,0.5,0.9
10000000,20,160,272,8,32,4,10,80,40,128,0.0494,1.0,0.0941,19.92,57,0.5,0.9
10000000,20,200,272,8,32,4,10,100,50,128,0.0431,1.0,0.0826,19.38,71,0.5,0.9
10000000,20,240,272,8,32,4,10,120,60,128,0.0378,1.0,0.0728,19.15,85,0.5,0.9
10000000,20,280,272,8,32,4,10,140,70,128,0.033,1.0,0.0639,19.25,99,0.5,0.9
10000000,20,320,272,8,32,4,10,160,80,128,0.0314,1.0,0.0609,18.89,114,0.5,0.9
10000000,20,360,272,8,32,4,10,180,90,128,0.0275,1.0,0.0535,20.55,128,0.5,0.9
10000000,20,400,272,8,32,4,10,200,100,128,0.0257,1.0,0.0501,21.11,142,0.5,0.9""",
        'ours': """10000000,20,20,272,8,32,4,10,10,5,1,272,16,0.8571,0.2857,0.4285,19.3,13,0.5,0.5
10000000,20,40,272,8,32,4,10,20,10,1,272,16,0.9375,0.7143,0.8108,19.65,26,0.5,0.5
10000000,20,60,272,8,32,4,10,30,15,1,272,16,0.9474,0.8571,0.9,19.02,40,0.5,0.5
10000000,20,80,272,8,32,4,10,40,20,1,272,16,0.9048,0.9048,0.9048,19.36,53,0.5,0.5
10000000,20,100,272,8,32,4,10,50,25,1,272,16,0.9545,1.0,0.9767,18.94,67,0.5,0.5
10000000,20,120,272,8,32,4,10,60,30,1,272,16,0.9524,0.9524,0.9524,19.08,80,0.5,0.5
10000000,20,140,272,8,32,4,10,70,35,1,272,16,0.9545,1.0,0.9767,20.37,94,0.5,0.5
10000000,20,160,272,8,32,4,10,80,40,1,272,16,0.9524,0.9524,0.9524,19.23,107,0.5,0.5
10000000,20,180,272,8,32,4,10,90,45,1,272,16,0.9545,1.0,0.9767,19.58,121,0.5,0.5
10000000,20,200,272,8,32,4,10,100,50,1,272,16,0.9545,1.0,0.9767,19.86,134,0.5,0.5
10000000,20,220,272,8,32,4,10,110,55,1,272,16,0.9545,1.0,0.9767,19.58,147,0.5,0.5"""
    },
    {
        'minhash': """10000000,20,20,272,8,32,4,10,10,5,200,0.5094,0.6429,0.5684,38.29,11,0.5,0.9
10000000,20,40,272,8,32,4,10,20,10,200,0.4416,0.8095,0.5715,36.23,22,0.5,0.9
10000000,20,60,272,8,32,4,10,30,15,200,0.375,0.7857,0.5077,37.13,34,0.5,0.9
10000000,20,80,272,8,32,4,10,40,20,200,0.37,0.881,0.5211,40.0,45,0.5,0.9
10000000,20,100,272,8,32,4,10,50,25,200,0.3302,0.8333,0.473,40.48,56,0.5,0.9
10000000,20,120,272,8,32,4,10,60,30,200,0.319,0.881,0.4684,42.02,68,0.5,0.9
10000000,20,140,272,8,32,4,10,70,35,200,0.2734,0.8333,0.4117,42.73,79,0.5,0.9
10000000,20,160,272,8,32,4,10,80,40,200,0.2606,0.881,0.4022,43.15,90,0.5,0.9
10000000,20,180,272,8,32,4,10,90,45,200,0.2517,0.881,0.3915,44.78,102,0.5,0.9
10000000,20,200,272,8,32,4,10,100,50,200,0.2574,0.8333,0.3933,45.42,113,0.5,0.9
10000000,20,220,272,8,32,4,10,110,55,200,0.269,0.9286,0.4172,53.91,124,0.5,0.9
10000000,20,240,272,8,32,4,10,120,60,200,0.2657,0.9048,0.4108,66.09,136,0.5,0.9""",
        'maxloghash': """10000000,20,40,272,8,32,4,10,20,10,128,0.0538,0.9048,0.1016,27.45,14,0.5,0.9
10000000,20,60,272,8,32,4,10,30,15,128,0.0471,1.0,0.09,20.41,21,0.5,0.9
10000000,20,80,272,8,32,4,10,40,20,128,0.0371,0.9762,0.0715,20.99,28,0.5,0.9
10000000,20,100,272,8,32,4,10,50,25,128,0.0317,0.9762,0.0614,22.45,35,0.5,0.9
10000000,20,120,272,8,32,4,10,60,30,128,0.0299,1.0,0.0581,22.63,42,0.5,0.9
10000000,20,140,272,8,32,4,10,70,35,128,0.0276,1.0,0.0537,24.83,49,0.5,0.9
10000000,20,160,272,8,32,4,10,80,40,128,0.0254,1.0,0.0495,19.25,57,0.5,0.9
10000000,20,180,272,8,32,4,10,90,45,128,0.0226,1.0,0.0442,19.94,64,0.5,0.9
10000000,20,200,272,8,32,4,10,100,50,128,0.0205,0.9762,0.0402,19.48,71,0.5,0.9
10000000,20,220,272,8,32,4,10,110,55,128,0.0198,1.0,0.0388,18.87,78,0.5,0.9
10000000,20,240,272,8,32,4,10,120,60,128,0.0191,1.0,0.0375,19.48,85,0.5,0.9
10000000,20,260,272,8,32,4,10,130,65,128,0.0178,0.9762,0.035,18.79,92,0.5,0.9
10000000,20,280,272,8,32,4,10,140,70,128,0.0171,1.0,0.0336,19.33,99,0.5,0.9
10000000,20,300,272,8,32,4,10,150,75,128,0.0164,1.0,0.0323,19.46,106,0.5,0.9
10000000,20,320,272,8,32,4,10,160,80,128,0.016,1.0,0.0315,18.67,114,0.5,0.9
10000000,20,340,272,8,32,4,10,170,85,128,0.0153,1.0,0.0301,19.63,121,0.5,0.9
10000000,20,360,272,8,32,4,10,180,90,128,0.0146,1.0,0.0288,20.41,128,0.5,0.9
10000000,20,380,272,8,32,4,10,190,95,128,0.0144,1.0,0.0284,18.17,135,0.5,0.9
10000000,20,400,272,8,32,4,10,200,100,128,0.0137,1.0,0.027,19.83,142,0.5,0.9""",
        'ours': """10000000,20,20,272,8,32,4,10,10,5,1,272,16,1.0,0.2619,0.4151,19.05,13,0.5,0.4
10000000,20,40,272,8,32,4,10,20,10,1,272,16,0.9444,0.4048,0.5667,16.7,26,0.5,0.4
10000000,20,60,272,8,32,4,10,30,15,1,272,16,0.9143,0.7619,0.8312,16.82,40,0.5,0.4
10000000,20,80,272,8,32,4,10,40,20,1,272,16,0.9394,0.7381,0.8267,17.68,53,0.5,0.4
10000000,20,100,272,8,32,4,10,50,25,1,272,16,0.9268,0.9048,0.9157,18.47,67,0.5,0.4
10000000,20,120,272,8,32,4,10,60,30,1,272,16,0.8293,0.8095,0.8193,18.95,80,0.5,0.4
10000000,20,140,272,8,32,4,10,70,35,1,272,16,0.814,0.8333,0.8235,19.18,94,0.5,0.4
10000000,20,160,272,8,32,4,10,80,40,1,272,16,0.875,0.8333,0.8536,19.69,107,0.5,0.4
10000000,20,180,272,8,32,4,10,90,45,1,272,16,0.8974,0.8333,0.8642,19.34,121,0.5,0.4
10000000,20,200,272,8,32,4,10,100,50,1,272,16,0.8667,0.9286,0.8966,19.25,134,0.5,0.4
10000000,20,120,272,8,32,4,10,60,30,1,272,16,0.9444,0.8095,0.8718,18.74,80,0.5,0.5
10000000,20,140,272,8,32,4,10,70,35,1,272,16,0.9286,0.9286,0.9286,19.29,94,0.5,0.5
10000000,20,160,272,8,32,4,10,80,40,1,272,16,0.973,0.8571,0.9114,20.07,107,0.5,0.5
10000000,20,180,272,8,32,4,10,90,45,1,272,16,0.9444,0.8095,0.8718,22.82,121,0.5,0.5"""
    },
    {
        'minhash': """10000000,20,20,272,8,32,4,10,10,5,200,0.2252,0.7576,0.3472,74.23,11,0.5,0.8
10000000,20,40,272,8,32,4,10,20,10,200,0.1849,0.8182,0.3016,73.82,22,0.5,0.8
10000000,20,60,272,8,32,4,10,30,15,200,0.1504,0.8636,0.2562,72.3,34,0.5,0.8
10000000,20,80,272,8,32,4,10,40,20,200,0.1477,0.9242,0.2547,75.48,45,0.5,0.8
10000000,20,100,272,8,32,4,10,50,25,200,0.1452,0.9545,0.2521,75.78,56,0.5,0.8
10000000,20,120,272,8,32,4,10,60,30,200,0.1484,0.9848,0.2579,76.79,68,0.5,0.8
10000000,20,140,272,8,32,4,10,70,35,200,0.1425,0.9848,0.249,78.9,79,0.5,0.8
10000000,20,160,272,8,32,4,10,80,40,200,0.1371,0.9848,0.2407,78.85,90,0.5,0.8
10000000,20,180,272,8,32,4,10,90,45,200,0.131,0.9848,0.2312,79.35,102,0.5,0.8
10000000,20,200,272,8,32,4,10,100,50,200,0.1346,0.9848,0.2368,81.31,113,0.5,0.8
10000000,20,220,272,8,32,4,10,110,55,200,0.1318,0.9848,0.2325,81.54,124,0.5,0.8
10000000,20,240,272,8,32,4,10,120,60,200,0.1265,0.9848,0.2242,79.99,136,0.5,0.8
10000000,20,260,272,8,32,4,10,130,65,200,0.1277,0.9848,0.2261,83.94,147,0.5,0.8""",
        'maxloghash': """10000000,20,20,272,8,32,4,10,10,5,128,0.1121,0.9848,0.2013,8.55,7,0.5,0.9
10000000,20,20,272,8,32,4,10,10,5,128,0.1121,0.9848,0.2013,8.84,7,0.5,0.9
10000000,20,20,272,8,32,4,10,10,5,128,0.1121,0.9848,0.2013,8.76,7,0.5,0.9
10000000,20,40,272,8,32,4,10,20,10,128,0.081,0.9697,0.1495,8.11,14,0.5,0.9
10000000,20,60,272,8,32,4,10,30,15,128,0.0672,0.9697,0.1257,7.59,21,0.5,0.9
10000000,20,80,272,8,32,4,10,40,20,128,0.0634,0.9848,0.1191,7.31,28,0.5,0.9
10000000,20,100,272,8,32,4,10,50,25,128,0.0607,0.9848,0.1144,7.28,35,0.5,0.9
10000000,20,120,272,8,32,4,10,60,30,128,0.0535,0.9848,0.1015,7.05,42,0.5,0.9
10000000,20,140,272,8,32,4,10,70,35,128,0.0535,0.9848,0.1015,7.06,49,0.5,0.9
10000000,20,160,272,8,32,4,10,80,40,128,0.0504,0.9848,0.0959,6.81,57,0.5,0.9
10000000,20,180,272,8,32,4,10,90,45,128,0.0462,0.9848,0.0883,6.9,64,0.5,0.9
10000000,20,200,272,8,32,4,10,100,50,128,0.0453,0.9848,0.0866,7.08,71,0.5,0.9
10000000,20,220,272,8,32,4,10,110,55,128,0.0459,0.9848,0.0877,7.23,78,0.5,0.9
10000000,20,240,272,8,32,4,10,120,60,128,0.0448,0.9848,0.0857,10.89,85,0.5,0.9
10000000,20,260,272,8,32,4,10,130,65,128,0.0433,0.9848,0.083,8.2,92,0.5,0.9
10000000,20,280,272,8,32,4,10,140,70,128,0.0426,0.9848,0.0817,9.63,99,0.5,0.9
10000000,20,300,272,8,32,4,10,150,75,128,0.0419,0.9848,0.0804,11.13,106,0.5,0.9
10000000,20,320,272,8,32,4,10,160,80,128,0.0406,0.9848,0.078,7.97,114,0.5,0.9
10000000,20,340,272,8,32,4,10,170,85,128,0.0401,0.9848,0.0771,6.88,121,0.5,0.9
10000000,20,360,272,8,32,4,10,180,90,128,0.0391,0.9848,0.0752,6.82,128,0.5,0.9
10000000,20,380,272,8,32,4,10,190,95,128,0.0381,0.9848,0.0734,6.44,135,0.5,0.9
10000000,20,400,272,8,32,4,10,200,100,128,0.0371,0.9848,0.0715,6.66,142,0.5,0.9""",
        'ours': """10000000,20,20,272,8,32,4,10,10,5,1,272,16,1.0,0.2727,0.4285,9.95,13,0.5,0.5
10000000,20,20,272,8,32,4,10,10,5,1,272,16,1.0,0.2879,0.4471,13.5,13,0.5,0.5
10000000,20,20,272,8,32,4,10,10,5,1,272,16,1.0,0.3485,0.5169,10.99,13,0.5,0.5
10000000,20,40,272,8,32,4,10,20,10,1,272,16,1.0,0.3485,0.5169,10.59,26,0.5,0.5
10000000,20,60,272,8,32,4,10,30,15,1,272,16,1.0,0.5152,0.68,11.64,40,0.5,0.5
10000000,20,80,272,8,32,4,10,40,20,1,272,16,1.0,0.5909,0.7428,12.43,53,0.5,0.5
10000000,20,100,272,8,32,4,10,50,25,1,272,16,1.0,0.7879,0.8814,13.31,67,0.5,0.5
10000000,20,120,272,8,32,4,10,60,30,1,272,16,0.9815,0.803,0.8833,14.06,80,0.5,0.5
10000000,20,140,272,8,32,4,10,70,35,1,272,16,1.0,0.8636,0.9268,15.09,94,0.5,0.5
10000000,20,160,272,8,32,4,10,80,40,1,272,16,1.0,0.8788,0.9355,15.01,107,0.5,0.5
10000000,20,180,272,8,32,4,10,90,45,1,272,16,0.9672,0.8939,0.9291,17.51,121,0.5,0.5
10000000,20,200,272,8,32,4,10,100,50,1,272,16,0.9833,0.8939,0.9365,19.38,134,0.5,0.5
10000000,20,220,272,8,32,4,10,110,55,1,272,16,0.9833,0.8939,0.9365,19.9,147,0.5,0.5"""
    },
    {
        'minhash': """10000000,20,20,272,8,32,32,32,10,5,200,1.0,0.6,0.75,134.65,11,0.5,0.9
10000000,20,60,272,8,32,32,32,30,15,200,0.8571,0.6,0.7059,113.31,34,0.5,0.9
10000000,20,100,272,8,32,32,32,50,25,200,0.75,0.9,0.8182,152.44,57,0.5,0.9
10000000,20,140,272,8,32,32,32,70,35,200,0.7273,0.8,0.7619,124.81,80,0.5,0.9
10000000,20,180,272,8,32,32,32,90,45,200,0.7273,0.8,0.7619,124.69,103,0.5,0.9
10000000,20,220,272,8,32,32,32,110,55,200,0.8333,1.0,0.9091,160.86,126,0.5,0.9
10000000,20,260,272,8,32,32,32,130,65,200,0.6667,0.8,0.7273,128.62,149,0.5,0.9
10000000,20,40,272,8,32,32,32,20,10,200,0.8889,0.8,0.8421,142.03,23,0.5,0.9
10000000,20,80,272,8,32,32,32,40,20,200,0.8182,0.9,0.8572,158.21,46,0.5,0.9
10000000,20,120,272,8,32,32,32,60,30,200,0.8,0.8,0.8,124.11,69,0.5,0.9
10000000,20,160,272,8,32,32,32,80,40,200,0.8,0.8,0.8,130.86,92,0.5,0.9
10000000,20,200,272,8,32,32,32,100,50,200,0.6429,0.9,0.75,164.16,115,0.5,0.9
10000000,20,240,272,8,32,32,32,120,60,200,0.6923,0.9,0.7826,129.28,138,0.5,0.9""",
        'maxloghash': """10000000,20,20,272,8,32,32,32,10,5,128,0.0926,1.0,0.1695,6.46,7,0.5,0.9
10000000,20,60,272,8,32,32,32,30,15,128,0.0173,0.9,0.0339,9.15,21,0.5,0.9
10000000,20,100,272,8,32,32,32,50,25,128,0.0168,1.0,0.033,7.3,36,0.5,0.9
10000000,20,120,272,8,32,32,32,60,30,128,0.0108,0.9,0.0213,8.29,43,0.5,0.9
10000000,20,140,272,8,32,32,32,70,35,128,0.0098,0.9,0.0194,8.47,50,0.5,0.9
10000000,20,160,272,8,32,32,32,80,40,128,0.0087,0.9,0.0172,9.2,58,0.5,0.9
10000000,20,180,272,8,32,32,32,90,45,128,0.008,0.9,0.0159,8.47,65,0.5,0.9
10000000,20,200,272,8,32,32,32,100,50,128,0.0122,1.0,0.0241,7.24,72,0.5,0.9
10000000,20,220,272,8,32,32,32,110,55,128,0.0103,1.0,0.0204,7.58,80,0.5,0.9
10000000,20,240,272,8,32,32,32,120,60,128,0.0065,0.9,0.0129,8.98,87,0.5,0.9
10000000,20,260,272,8,32,32,32,130,65,128,0.0064,0.9,0.0127,9.22,94,0.5,0.9
10000000,20,280,272,8,32,32,32,140,70,128,0.0083,1.0,0.0165,7.0,101,0.5,0.9
10000000,20,300,272,8,32,32,32,150,75,128,0.008,1.0,0.0159,7.63,109,0.5,0.9
10000000,20,340,272,8,32,32,32,170,85,128,0.0071,1.0,0.0141,7.16,123,0.5,0.9
10000000,20,380,272,8,32,32,32,190,95,128,0.005,0.9,0.0099,9.5,138,0.5,0.9
10000000,20,420,272,8,32,32,32,210,105,128,0.0046,0.9,0.0092,8.59,152,0.5,0.9""",
        'ours': """10000000,20,20,272,8,32,32,32,10,5,1,272,16,1.0,0.7,0.8235,15.52,13,0.5,0.7
10000000,20,40,272,8,32,32,32,20,10,1,272,16,1.0,0.9,0.9474,13.99,27,0.5,0.7
10000000,20,60,272,8,32,32,32,30,15,1,272,16,0.8889,0.8,0.8421,11.9,40,0.5,0.7
10000000,20,80,272,8,32,32,32,40,20,1,272,16,0.9,0.9,0.9,15.17,54,0.5,0.7
10000000,20,100,272,8,32,32,32,50,25,1,272,16,1.0,1.0,1.0,17.86,68,0.5,0.7
10000000,20,120,272,8,32,32,32,60,30,1,272,16,0.9,0.9,0.9,15.0,81,0.5,0.7
10000000,20,140,272,8,32,32,32,70,35,1,272,16,0.9,0.9,0.9,15.74,95,0.5,0.7
10000000,20,160,272,8,32,32,32,80,40,1,272,16,0.9,0.9,0.9,15.71,108,0.5,0.7
10000000,20,180,272,8,32,32,32,90,45,1,272,16,0.9,0.9,0.9,16.73,122,0.5,0.7
10000000,20,200,272,8,32,32,32,100,50,1,272,16,1.0,1.0,1.0,20.95,136,0.5,0.7
10000000,20,220,272,8,32,32,32,110,55,1,272,16,0.9091,1.0,0.9524,20.73,149,0.5,0.7"""
    }
]

# ======== 绘图风格 =============
plt.rcParams.update({
    'font.size': 24,
    'axes.titlesize': 24,
    'axes.labelsize': 24,
    'xtick.labelsize': 24,
    'ytick.labelsize': 24,
    'legend.fontsize': 24,
    'font.family': 'Times New Roman',
    'pdf.fonttype': 42,
    'ps.fonttype': 42,
    'text.usetex': False,
})
colors = sns.color_palette("tab10")
markers = {'ours': 'o', 'minhash': 's', 'maxloghash': '^'}
linestyles = {'ours': '-', 'minhash': '--', 'maxloghash': ':'}

# ======== 列名 ============
columns_common = [
    'packet_size', 'entry_size', 'filter1_d', 'filter1_w', 'filter1_ct',
    'flow_id_size', 'simi_size', 'timestamp_size', 'filter2_main_num',
    'filter2_alter_num'
]
columns_user = columns_common + ['cm_depth', 'cm_width', 'cm_ct', 'precision', 'recall', 'f1-score',
                                 'insert-time', 'space(KB)', 'filter1_threshold', 'filter2_threshold']
columns_minhash = columns_common + ['k_minhash', 'precision', 'recall', 'f1-score', 'insert-time', 'space(KB)',
                                    'filter1_threshold', 'filter2_threshold']
columns_maxloghash = columns_common + ['k', 'precision', 'recall', 'f1-score', 'insert-time', 'space(KB)',
                                       'filter1_threshold', 'filter2_threshold']

# ======== 数据处理函数 ============
def parse_dataframe(data_str, columns, method):
    df = pd.DataFrame([line.split(',') for line in data_str.strip().split('\n')], columns=columns)
    df['method'] = method
    numeric_cols = ['space(KB)', 'precision', 'recall', 'f1-score', 'insert-time']
    for col in numeric_cols:
        df[col] = df[col].astype(float)
    return df

# ======== 合并所有数据集 ============
all_datasets = []

for idx, config in enumerate(dataset_configs):
    raw = dataset_raw_data[idx]
    total_pos = config['positives']
    total_samples = config['samples']
    total_neg = total_samples - total_pos

    df_minhash = parse_dataframe(raw['minhash'], columns_minhash, 'minhash')
    df_maxloghash = parse_dataframe(raw['maxloghash'], columns_maxloghash, 'maxloghash')
    df_user = parse_dataframe(raw['ours'], columns_user, 'ours')

    group_keys = columns_common + ['cm_depth', 'cm_width', 'cm_ct']
    df_user_filtered = df_user.loc[df_user.groupby(group_keys)['precision'].idxmax()]
    df_combined = pd.concat([df_minhash, df_maxloghash, df_user_filtered])
    df_combined = df_combined.sort_values(by='space(KB)')

    df_combined['dataset'] = config['name']
    all_datasets.append(df_combined)

# 合并4个数据集
df_all = pd.concat(all_datasets, ignore_index=True)

# ======== 绘图：一行4图的 Precision ============
fig, axes = plt.subplots(1, 4, figsize=(24, 5), sharey=False, constrained_layout=True)

for i, (dataset_name, group) in enumerate(df_all.groupby('dataset')):
    ax = axes[i]
    for j, (method, subgrp) in enumerate(group.groupby('method')):
        subgrp_sorted = subgrp.sort_values('space(KB)')
        ax.plot(subgrp_sorted['space(KB)'], subgrp_sorted['precision'],
                label=method,
                marker=markers[method],
                linestyle=linestyles[method],
                linewidth=2,
                markersize=8,
                color=colors[j])
    ax.annotate(f"({chr(ord('a') + i)}) {dataset_name}",
                xy=(0.5, -0.3),  # 控制垂直偏移，数值可微调
                xycoords='axes fraction',
                ha='center', va='center',
                fontweight='bold')
    ax.set_xlabel('Memory(KB)', fontweight='bold')
    if i == 0:
        ax.set_ylabel('Precision', fontweight='bold')
    ax.grid(True, linestyle='--', alpha=0.6)

# 图例
handles, labels = axes[0].get_legend_handles_labels()
fig.legend(handles, labels, loc='upper center', ncol=3, frameon=True,
           bbox_to_anchor=(0.5, 1.15), edgecolor='black', prop={'weight': 'bold'})

# 保存
plt.savefig('fig/precision_across_datasets.pdf', bbox_inches='tight')
# plt.show()
# 绘图代码保持不变（只绘图不打印）

# 统一输出所有数值，方便数值分析
print("==== All Precision Data Points ====")
for dataset_name, group in df_all.groupby('dataset'):
    print(f"Dataset: {dataset_name}")
    for method, subgrp in group.groupby('method'):
        subgrp_sorted = subgrp.sort_values('space(KB)')
        print(f"  Method: {method}")
        for _, row in subgrp_sorted.iterrows():
            print(f"    space(KB): {row['space(KB)']:.3f}, precision: {row['precision']:.4f}")
